pytorch:
    adapter: "timm" # torchvision or timm
    task: "classification"
    # model name references:
    # https://pytorch.org/vision/stable/models.html#classification
    # https://huggingface.co/docs/timm/reference/models#timm.list_models
    model_name: "vgg16" # resnet18 efficientnet_v2_s vgg11-19 vgg16 mobilenet_v3_small
    weights: "DEFAULT" # updated since torchvision v0.13. Refer to official doc for customized values.
    pretrained: True # for timm only
    fine_tune: True
    unfreeze: "partial" # all (unfreeze all layers) | none (unfreeze the classifier only) | partial (unfreeze the classifier and part of the backbone)
    fine_tune_modules: # valid when unfreeze == "partial". module name followed by the number of the last layers within the module to unfreeze.
        pre_logits: ["fc1", "fc2"]
        features: 3

    model_type:
        _target_: src.model.pytorch_model.PTClassificationModel
    num_classes: ${data_module.dataset.num_classes}
    device: ${device}
    # You typically want _self_ somewhere after the schema (base_config)

tensorflow:
    task: "classification"
    model_name: "VGG16" # VGG16 ResNet50 EfficientNetV2S
    model_type:
        _target_: src.model.tensorflow_model.TFClassificationModelFactory
    num_classes: ${data_module.dataset.num_classes}
    image_size: ${data_module.dataset.image_size}
    device: ${device}
    pretrained: True
    # unfreeze_layers: -1 # -1 (All) | int (Last N Layers) | 0 (Freeze All)
    fine_tune: True # True or False
    fine_tune_layers: [
            "prediction_modified",
            "fc1",
            "fc2",
            "block5_pool",
            "block5_conv3",
            "block5_conv2",
            "block5_conv1",
        ] # prediction layer need to be included. If not, the weights will not be updated
    dropout_rate: 0.3
